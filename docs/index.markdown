---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default

irosVideoId: 1wag5m_uDBRPMmNiLkZLFNsktBMZdmMVH/preview
scitechVideoId: 1uBUFSIgVYbPKJCdrHyqZY6C_G0I2rYps/preview

irosYouTubeId: k-eM6Locyek
scitechYouTubeId: qmoHyJFUxE0
neuripsWorkshop2022YouTubeId: Ft2bozofYM8

---
**[Publications](#Publications) &ensp; &ensp; &ensp; &ensp; [Presentations](#Presentations) &ensp; &ensp; &ensp; &ensp; [Coursework](#Education) &ensp; &ensp; &ensp; &ensp; [CV](./files/Kyle_Hatch_CV_December_2022.pdf){:target="_blank"} &ensp; &ensp; &ensp; &ensp; [Volunteer Work](#Volunteer)**

<!-- <img src="./files/j_tree_portrait_clipped_small.png" alt="drawing" width="200"/> -->
<!-- <img src="./files/j_tree_portrait_clipped_small.png" alt="drawing" width="275"/> -->
<!-- <img src="./files/j_tree_portrait_clipped_small.png" alt="drawing" width="250"/> -->

<img src="./files/j_tree_portrait_clipped_small.png" alt="drawing" align="left" width="275" style="margin: 0px 30px 0px 0px;" />

I am a master's student at Stanford University studying Computer Science.
<!-- I am heavily involved in artificial intelligence research and  -->
I plan to pursue a PhD in Computer Science, Machine Learning, or Robotics.
My research interests lie primarily within reinforcement learning (RL) and robot learning.
I am especially fascinated with answering the following questions:
  - How can we make RL agents that can generalize quickly and efficiently to new tasks?
  - How can we make RL algorithms that leverage prior knowledge about a task during training instead of training from *tabula rasa?*
<!-- <br clear="left"/> -->


Currently, I am conducting research in the Stanford [IRIS](https://irislab.stanford.edu/){:target="_blank"} Lab under Professor [Chelsea Finn](https://ai.stanford.edu/~cbfinn/){:target="_blank"}, where I am developing an offline RL method that uses contrastive learning to solve continuous control tasks without reward labels.
<!-- where I am developing an offline RL algorithm for heterogeneous datasets that don't have reward labels.  -->
I previously conducted research in the Stanford Intelligent Systems Laboratory ([SISL](https://sisl.stanford.edu/){:target="_blank"}) under Professor [Mykel Kochenderfer](https://mykel.kochenderfer.com/){:target="_blank"}, where I conducted research on using RL for autonomous vehicle safety and control. I also worked as a research intern on a collaborative project between SISL and the Johns Hopkins University Applied Physics Laboratory ([APL](https://www.jhuapl.edu/){:target="_blank"})  on developing RL based methods to defend industrial control systems against cyber attacks.

<html>
 <head>
    <style>
    {
        box-sizing: border-box;
    }
    /* Set additional styling options for the columns*/
    .column {
    float: left;
    width: 50%;
    }

    .row:after {
    content: "";
    display: table;
    clear: both;
    }
    </style>
 </head>
 <body>
    <div class="row">
        <div class="column">
            <h5>Research Interests</h5>
            <p>
              <ul>
                <li>Leveraging Prior Knowledge in RL</li>
                <li>Generalization in RL</li>
                <li>Offline RL</li>
                <li>Robot Learning</li>
              </ul>
            </p>
        </div>
        <div class="column">
            <h5>Education</h5>
            <p>
              <ul>
                <li>M.S. in Computer Science, Stanford University, 2021 - Present</li>
                <li>B.S. in Computer Science, Stanford University, 2017 - 2022</li>
              </ul>
            </p>
        </div>
    </div>
 </body>
</html>


<a name="Publications"> </a>
## Publications

#### Under Review

**Hatch, K. B.,** Eysenbach, B., Yu, T., Rafailov, R., Salakhutdinov, R., Levine, S., and Finn, C., ”Contrastive
Example-Based Control,” *Learning for Dynamics & Control Conference (L4DC),* 2023. [PDF](//drive.google.com/file/d/1mLi1vZlqRcqxp89RHPAIH-gQC7lb7UTk/view?usp=sharing){:target="_blank"}

Zhou, G., Dean, V., Srirama, M. K., Rajeswaran, A., Pari, J., **Hatch, K. B.,** Jain, A., Yu, T., Abbeel, P., Pinto, L., Finn, C., and Gupta, A., “Train Offline, Test Online: A Real Robot Learning Benchmark,” *2023 IEEE International Conference on Robotics and Automation (ICRA),* 2023. [Website](https://toto-benchmark.org/){:target="_blank"}

#### Published/Accepted

Mern, J., **Hatch, K.,** Silva, R., Hickert, C., Sookoor, T., and Kochenderfer, M. J., "Autonomous Attack Mitigation for Industrial Control Systems," *International Conference on Dependable Systems and Networks (DSN'22),* 2022, pp. 28–36.
&ensp; [PDF](https://arxiv.org/abs/2111.02445){:target="_blank"}

Mern, J., Krishnan, S., Yildiz, A., **Hatch, K.,** and Kochenderfer, M. J., "Interpretable Local Tree Surrogate Policies,"  *The AAAI Workshop on Artificial Intelligence Safety 2022 (SafeAI),* 2022. &ensp; [PDF](https://arxiv.org/abs/2109.08180){:target="_blank"}

Senanayake, R.\*, **Hatch, K.\*,** Zheng, J., and Kochenderfer, M. J., "3D Radar Velocity Maps for Uncertain Dynamic Environments," *IEEE International Conference on Intelligent Robots and Systems (IROS),* 2021. &ensp; [PDF](https://arxiv.org/abs/2107.11039){:target="_blank"} &ensp; &ensp; [Presentation](#iros_video)

**Hatch, K.,** Mern, J., and Kochenderfer, M. J., "Obstacle Avoidance Using a Monocular Camera," *AIAA SciTech Forum,* 2021. &ensp; [PDF](https://arxiv.org/abs/2012.01608){:target="_blank"} &ensp; &ensp; [Presentation](#scitech_video)

#### Workshop Papers

**Hatch, K. B.,** Shetty, S. J., Eysenbach, B., Yu, T., Rafailov, R., Salakhutdinov, R., Levine, S., and Finn, C., "Contrastive Example-Based Control," *NeurIPS 2022 Offline RL and Deep RL Workshops,* 2022. [PDF](https://openreview.net/forum?id=Q4ir4NzqOY){:target="_blank"}

**Hatch, K.\*,**Yu, T.\*, Rafailov, R., and Finn, C., "Example-Based Offline Reinforcement Learning without Rewards," *NeurIPS Offline RL Workshop,* 2021.

<!-- **Hatch, K.\*,** Yu, T.\*, Rafailov, R., and Finn, C., "Example-Based Offline Reinforcement Learning without Rewards." Learning for Dynamics & Control Conference (L4DC), 2022. &ensp; [PDF](./files/Offline_RL_without_Rewards.pdf){:target="_blank"} -->

<!-- Mern, J., **Hatch, K.,** Silva, R., Hickert, C., Sookoor, T., and Kochenderfer, M. J., "Autonomous Attack Mitigation for Industrial Control Systems," USENIX Security Symposium, 2021. &ensp; [PDF](https://arxiv.org/abs/2111.02445){:target="_blank"} -->
<!-- Mern, J., **Hatch, K.,** Silva, R., Hickert, C., Sookoor, T., and Kochenderfer, M. J., "Autonomous Attack Mitigation for Industrial Control Systems," International Conference on Dependable Systems and Networks (DSN'22), 2022. &ensp; [PDF](https://arxiv.org/abs/2111.02445){:target="_blank"} -->


**\* denotes equal contribution**

<a name="Presentations"> </a>
## Presentations

<a name="iros_video"> </a>
**"Offline Example-Based Control," NeurIPS Offline RL and Deep RL Workshops, 2022.**
{% include youtubePlayer.html id=page.neuripsWorkshop2022YouTubeId %}

&nbsp;
&nbsp;
&nbsp;



<a name="iros_video"> </a>
**"3D Radar Velocity Maps for Uncertain Dynamic Environments," IEEE International Conference on Intelligent Robots and Systems (IROS), 2021.**
{% include youtubePlayer.html id=page.irosYouTubeId %}

&nbsp;
&nbsp;
&nbsp;

<a name="scitech_video"> </a>
**“Obstacle Avoidance Using a Monocular Camera,” AIAA SciTech Forum, 2021.**
{% include youtubePlayer.html id=page.scitechYouTubeId %}


<a name="Education"> </a>
## Education

#### Master's GPA: 4.11

<!-- #### Artificial Intelligence, Machine Learning, and Other Relevant Coursework -->
#### Relevant Coursework

<html>
 <head>
   <style type="text/css">
    ul {
     list-style-type: none;
    }
   </style>
    <style>
    {
        box-sizing: border-box;
    }
    /* Set additional styling options for the columns*/
    <!-- .col0 {
    float: left;
    width: 70%;
    }

    .col1 {
    float: left;
    width: 13%;
    }

    .col2 {
    float: left;
    width: 14%;
    } -->
    .col0 {
    float: left;
    width: 87%;
    }

    .col1 {
    float: left;
    width: 13%;
    }


    .row:after {
    content: "";
    display: table;
    clear: both;
    }
    </style>
 </head>
 <body>
    <div class="row">
        <div class="col0">
            <h5> Class </h5>
            <p>
              <ul>
                <li>CS 332: Advanced Survey of Reinforcement Learning</li>
                <li>MS&E 338: Reinforcement Learning: Frontiers</li>
                <li>CS 239: Advanced Topics in Sequential Decision Making</li>
                <li>CS 224N: Natural Language Processing with Deep Learning</li>
                <li>CS 330: Deep Multi-task and Meta Learning</li>
                <li>CS 231N: Convolutional Neural Networks for Visual Recognition</li>
                <li>CS 234: Reinforcement Learning</li>
                <li>CS 205L: Continuous Mathematics with an Emphasis on Machine Learning</li>
                <li>CS 224W: Machine Learning with Graphs</li>
                <li>CS 221: Artificial Intelligence: Principles and Techniques</li>
                <li>CS 238: Decision Making Under Uncertainty</li>
                <li>MATH 104: Applied Matrix Theory</li>
                <li>CS 110: Principles of Computer Systems</li>
              </ul>
            </p>
        </div>

        <div class="col1">
            <h5>Grade</h5>
            <p>
              <ul>
                <li>  <font size="-2"> <em>in progress</em> </font> </li>
                <li>A</li>
                <li>A+</li>
                <li>A</li>
                <li>A</li>
                <li>S*</li>
                <!-- <li>.</li> -->
                <li>A</li>
                <li>A+</li>
                <!-- <li>.</li> -->
                <li>A-</li>
                <li>A</li>
                <li>A</li>
                <li>A</li>
                <li>A</li>
              </ul>
            </p>
        </div>

        <!-- <div class="col2">
            <h5>Quarter</h5>
            <p>
              <ul>
                <li>Fall 2022</li>
                <li>Spr 2022</li>
                <li>Win 2022</li>
                <li>Win 2022</li>
                <li>Fall 2021</li>
                <li>Spr 2020</li>
                <li>.</li>
                <li>Win 2020</li>
                <li>Win 2020</li>
                <li>.</li>
                <li>Fall 2019</li>
                <li>Spr 2019</li>
                <li>Fall 2018</li>
              </ul>
            </p>
        </div> -->
    </div>
 </body>
</html>

\* Letter grades not offered during the Spr 2020 quarter due to the COVID-19 pandemic.


<a name="Volunteer"> </a>
## Volunteer Work

#### East Palo Alto Stanford Academy ([EPASA](https://haas.stanford.edu/student-programs/education-partnerships/east-palo-alto-stanford-academy-epasa){:target="_blank"})
*October 2018 – March 2020*

*Volunteer Tutor*



[EPASA](https://haas.stanford.edu/student-programs/education-partnerships/east-palo-alto-stanford-academy-epasa){:target="_blank"} is a program run through Stanford University in which undergraduate students tutor middle school students who attend school in East Palo Alto.
As a volunteer tutor at EPASA, I tutored seventh and eighth grade students in math and English.

#### Stanford 1st Ward Volunteer Tutoring Program
*September 2017 – June 2019*

*Volunteer Tutor*

The Stanford 1st Ward Volunteer Tutoring Program is a program run through a local religious organization that provides free tutoring to K-12 students from around the South San Francisco Bay Area.
As a volunteer tutor, I tutored students in math, reading, and English.
