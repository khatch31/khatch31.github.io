---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
# title: "Kyle Hatch"
# subtitle: "This is a subtitle"



irosVideoId: 1wag5m_uDBRPMmNiLkZLFNsktBMZdmMVH/preview
scitechVideoId: 1uBUFSIgVYbPKJCdrHyqZY6C_G0I2rYps/preview

irosYouTubeId: k-eM6Locyek
scitechYouTubeId: qmoHyJFUxE0
neuripsWorkshop2022YouTubeId: Ft2bozofYM8
ghilglueYouTubeId: 3z8n1PWBFEA
---


<!-- **[Research](#Research) &ensp; &ensp; [Education](#Education) &ensp; &ensp; [CV](./files/Kyle_Hatch_CV_October_2023.pdf){:target="_blank"} &ensp; &ensp;  [Publications](#Publications) &ensp; &ensp; [Presentations](#Presentations) &ensp; &ensp; [Outreach](#Volunteer)**  -->
 **[CV](./files/Kyle_Hatch_CV.pdf){:target="_blank"} &ensp; &ensp; [Education](#Education) &ensp; &ensp; [Publications](#Publications) &ensp; &ensp; [Google Scholar](https://scholar.google.com/citations?user=ECrCBgQAAAAJ&hl=en){:target="_blank"} &ensp; &ensp; [Outreach](#Volunteer) &ensp; &ensp; [Presentations](#Presentations)**  
 Email: [kyle.hatch@tri.global](mailto:kyle.hatch@tri.global)  

<!-- **[CV](./files/Kyle_Hatch_CV_October_2023.pdf){:target="_blank"} &ensp; [Education](#Education) &ensp; [Publications](#Publications) &ensp; [Outreach](#Volunteer) &ensp; [Presentations](#Presentations) &ensp; [kyle.hatch@tri.global](mailto:kyle.hatch@tri.global)**   -->
 

<img src="./files/j_tree_portrait_clipped_small.png" alt="drawing" align="left" width="275" style="margin: 0px 30px 0px 0px;" />


I am an AI Resident in the Robotics Division at the [Toyota Research Institute](https://www.tri.global/){:target="_blank"} (TRI). 
I plan to pursue a PhD in Computer Science, Machine Learning, or Robotics. 
My research interests lie primarily within machine learning, robotics, and reinforcement learning (RL). 
Within robotics, I am especially excited about training large-scale models on human video data from the Internet in order to provide robots with common sense reasoning abilities.
I am also interested in using machine learning to help solve problems in healthcare and renewable energy. 
Previously, I was a student at Stanford, where I studied Computer Science (B.S. with honors and M.S.).




<!-- I am especially excited about exploring solutions to the following questions:
How can we leverage foundation models that can reason about both visual and language information for robot learning?
How can we utilize video data--which exists on a massive scale on the Internet but does not contain action labels--for training robot policies?
Can we use goal-conditioned/self-supervised RL to learn from random play data or autonomously collected robot data?  -->

I am extremely fortunate to have worked with many wonderful mentors during my time as a master's and undergraduate student. I worked with Prof. [Chelsea Finn](https://ai.stanford.edu/~cbfinn/){:target="_blank"} in the Stanford [IRIS](https://irislab.stanford.edu/){:target="_blank"} Lab as an undergraduate and master's student. 
<!-- As a master's student, I also worked with Prof. [Ben Eysenbach](https://ben-eysenbach.github.io/){:target="_blank"}. -->
I also worked with Prof. [Mykel Kochenderfer](https://mykel.kochenderfer.com/){:target="_blank"} as an undergraduate student in the Stanford Intelligent Systems Laboratory ([SISL](https://sisl.stanford.edu/){:target="_blank"}).
<!-- , and also completed a research internship at the Johns Hopkins University Applied Physics Laboratory ([APL](https://www.jhuapl.edu/){:target="_blank"}). -->


In my free time, I enjoy backpacking in the mountains, playing soccer, and watching horror movies. 

<a name="Education"> </a>
### Education  

**Stanford University**
&ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp;
**Stanford, CA**  
*M.S. in Computer Science*
&ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp;
Graduated: June 2023   
Artificial Intelligence Track
&ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp;
Coterminal Master’s Program  

**Stanford University**
&ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp;
**Stanford, CA**  
*B.S. in Computer Science with honors*&ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &nbsp;
Graduated: June 2022   
Artificial Intelligence Track


<a name="Publications"> </a>
## Publications

For a complete list of publications, please see my [Google Scholar profile](https://scholar.google.com/citations?user=ECrCBgQAAAAJ&hl=en){:target="_blank"}. 

#### Published/Accepted

<a name="cwm"> </a>
Rafailov, R.\*, Kolev, V.\*,  **Hatch, K. B.**, Wu, J., and Finn, C., ”Efficient Imitation Learning with Conservative World Models,” *Learning for Dynamics & Control Conference (L4DC),* 2024. &ensp; [PDF](https://arxiv.org/abs/2405.13193){:target="_blank"}


<a name="d5rl"> </a>
Rafailov, R.\*, **Hatch, K. B.\***, Singh, A., Smith, L., Kumar, A., Kostrikov, I., Hansen-Estruch, P., Kolev, V.,
Ball, P., Wu, J., Finn, C., and Levine, S., "D5RL: Diverse Datasets for Data-Driven Deep Reinforcement
Learning,” *Reinforcement Learning Conference (RLC),* 2024. &ensp; [PDF](https://rlj.cs.umass.edu/2024/papers/RLJ_RLC_2024_305.pdf){:target="_blank"}

<a name="moto"> </a>
Rafailov, R.\*, **Hatch, K. B.\***, Kolev, V., Martin, J., Phielipp, M., and Finn, C., ”MOTO: Offline to Online
Fine-tuning for Model-Based Reinforcement Learning,” *Conference on Robot Learning (CoRL)*, 2023. &ensp; [PDF](https://arxiv.org/abs/2401.03306){:target="_blank"} &ensp; &ensp; [Website](https://sites.google.com/view/mo2o){:target="_blank"}

<a name="laeo"> </a>
**Hatch, K. B.,** Eysenbach, B., Yu, T., Rafailov, R., Salakhutdinov, R., Levine, S., and Finn, C., ”Contrastive
Example-Based Control,” *Learning for Dynamics & Control Conference (L4DC),* 2023. &ensp; [PDF](https://arxiv.org/abs/2307.13101){:target="_blank"} &ensp; &ensp; [Website](https://sites.google.com/view/laeo-rl){:target="_blank"} &ensp; &ensp; [Presentation (NeurIPS workshop version)](#laeo_neurips_video) 

Zhou, G., Dean, V., Srirama, M. K., Rajeswaran, A., Pari, J., **Hatch, K. B.,** Jain, A., Yu, T., Abbeel, P., Pinto, L., Finn, C., and Gupta, A., “Train Offline, Test Online: A Real Robot Learning Benchmark,” *2023 IEEE International Conference on Robotics and Automation (ICRA),* 2023. &ensp; [PDF](https://arxiv.org/abs/2306.00942){:target="_blank"} &ensp; &ensp;  [Website](https://toto-benchmark.org/){:target="_blank"} 

<a name="apl_paper"> </a>
Mern, J., **Hatch, K.,** Silva, R., Hickert, C., Sookoor, T., and Kochenderfer, M. J., "Autonomous Attack Mitigation for Industrial Control Systems," *2022 IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),* 2022, pp. 28–36.
&ensp; [PDF](https://arxiv.org/abs/2111.02445){:target="_blank"}

<a name="iros_paper"> </a>
Senanayake, R.\*, **Hatch, K.\*,** Zheng, J., and Kochenderfer, M. J., "3D Radar Velocity Maps for Uncertain Dynamic Environments," *IEEE International Conference on Intelligent Robots and Systems (IROS),* 2021. &ensp; [PDF](https://arxiv.org/abs/2107.11039){:target="_blank"} &ensp; &ensp; [Presentation](#iros_video)

<a name="scitech_paper"> </a>
**Hatch, K.,** Mern, J., and Kochenderfer, M. J., "Obstacle Avoidance Using a Monocular Camera," *AIAA SciTech Forum,* 2021. &ensp; [PDF](https://arxiv.org/abs/2012.01608){:target="_blank"} &ensp; &ensp; [Presentation](#scitech_video)

#### Under Review

<a name="ghilglue"> </a>
**Hatch, K.,**, Balakrishna, A., Mees, O., Nair, S., Wulfe, B., Itkina, M., Eysenbach, B., Levine, S., Kollar, T., and Burchfiel, B., "GHIL-Glue: Hierarchical Control with Filtered Subgoal Images," *2025 IEEE International Conference on Robotics and Automation (ICRA),* 2025. &ensp; [PDF](https://arxiv.org/abs/2410.20018){:target="_blank"} &ensp; &ensp; [Website](https://ghil-glue.github.io/){:target="_blank"} &ensp; &ensp; [Presentation](#ghilglue_video) 



**\* denotes equal contribution**




<!-- <a name="Research"> </a>
## Research

At TRI, I am researching how to leverage Internet scale video data for robot learning. Videos of humans interacting with objects are available on a massive scale on the Internet, but this type of data does not contain the action labels needed to directly train a robot policy. In order to utilize this data, I am developing a hierarchical imitation learning-based approach that trains a high-level policy on action-free video data to output subgoals, which can then be reached by a low-level robot policy.


Prior to starting at TRI, I was a master's student in the Computer Science Department at Stanford University and conducted research under Prof. [Chelsea Finn](https://ai.stanford.edu/~cbfinn/){:target="_blank"} in the Stanford [IRIS](https://irislab.stanford.edu/){:target="_blank"} Lab. In Prof. Finn's group, my research focused on addressing three key limitations in scaling offline RL methods to realistic robot applications: 1) learning from play data/autonomously collected robot data without reward labels 2) pretraining on offline data and then finetuning online 3) and developing realistic simulated benchmarks. I published three first/co-first author papers on this research: 

1. [D5RL](#d5rl): a simulated robotics benchmark to evaluate offline RL methods on visually diverse, realistic simulated robotics tasks. Co-first author on paper under review at the International Conference on Learning Representations (ICLR) 2024.
2. [MOTO](#moto): a model-based RL method designed for efficient offline-to-online finetuning for vision-based manipulation tasks. Co-first author on paper in the Conference on Robot Learning (CoRL) 2023.
3. [LAEO](#laeo): an offline reinforcement learning method using contrastive learning for data without reward labels. First author on paper in the Learning for Dynamics & Control Conference (L4DC) 2023.

As an undergraduate student, I worked on research under Prof. [Mykel Kochenderfer](https://mykel.kochenderfer.com/){:target="_blank"} in the Stanford Intelligent Systems Laboratory ([SISL](https://sisl.stanford.edu/){:target="_blank"}). I also interned at the Johns Hopkins University Applied Physics Laboratory ([APL](https://www.jhuapl.edu/){:target="_blank"}). My research focused on using machine learning and RL techniques to improve collision avoidance in autonomous vehicles and UAVs, as well as using RL to autonomously mitigate cybersecurity threats. I published two first/co-first author papers and one second author paper on this research. 
1. A [method](#iros_paper) to learn 3D velocity maps from radar data for use by autonomous vehicles. Co-first author on paper in the IEEE International Conference on Intelligent Robots and Systems (IROS) 2021.
2. A [collision avoidance system](#scitech_paper) for autonomous drones using monocular vision and deep reinforcement learning. First author on paper in the American Institute of Aeronautics and Astronautics (AIAA) SciTech Forum 2021.
3. An [RL-based method](#apl_paper) for autonomously responding to cybersecurity threats on industrial control systems. Second author on paper in the International Conference on Dependable Systems and Networks (DSN’22), 2022. -->

<a name="Volunteer"> </a>
## Outreach

#### Breakthrough Silicon Valley ([BTSV](https://breakthroughsv.org){:target="_blank"})
*November 2023 – April 2024*

*Volunteer Tutor*


[Breakthrough Silicon Valley](https://breakthroughsv.org){:target="_blank"} is an organization that provides academic support to middle school and high school students who are on track to becoming first-generation college students. I primarily provide homework support to high school students with mathematics.


#### East Palo Alto Stanford Academy ([EPASA](https://haas.stanford.edu/student-programs/education-partnerships/east-palo-alto-stanford-academy-epasa){:target="_blank"})
*October 2018 – March 2020*

*Volunteer Tutor*


[EPASA](https://haas.stanford.edu/student-programs/education-partnerships/east-palo-alto-stanford-academy-epasa){:target="_blank"} is a program run through Stanford University in which undergraduate students tutor middle school students who attend school in East Palo Alto.
I provided homework support to seventh and eighth grade students in math and English, and also helped them to develop effective study skills.

#### Stanford 1st Ward Volunteer Tutoring Program
*September 2017 – June 2019*

*Volunteer Tutor*

The Stanford 1st Ward Volunteer Tutoring Program is a program run through a local religious organization that provides free tutoring to K-12 students from around the South San Francisco Bay Area.
I provided homework support students in math, reading, and English.


<a name="Presentations"> </a>
## Video Presentations

<!-- <details open>
  <summary>Collapse</summary> -->


<a name="ghilglue_video"> </a>
**"GHIL-Glue: Hierarchical Control with Filtered Subgoal Images"**
{% include youtubePlayer.html id=page.ghilglueYouTubeId %}

&nbsp;
&nbsp;
&nbsp;

<a name="laeo_neurips_video"> </a>
**"Offline Example-Based Control," NeurIPS Offline RL and Deep RL Workshops, 2022.**
{% include youtubePlayer.html id=page.neuripsWorkshop2022YouTubeId %}

&nbsp;
&nbsp;
&nbsp;



<a name="iros_video"> </a>
**"3D Radar Velocity Maps for Uncertain Dynamic Environments," IEEE International Conference on Intelligent Robots and Systems (IROS), 2021.**
{% include youtubePlayer.html id=page.irosYouTubeId %}

&nbsp;
&nbsp;
&nbsp;

<a name="scitech_video"> </a>
**“Obstacle Avoidance Using a Monocular Camera,” AIAA SciTech Forum, 2021.**
{% include youtubePlayer.html id=page.scitechYouTubeId %}

<!-- </details> -->
